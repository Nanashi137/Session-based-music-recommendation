{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from model import SAE_wrapper\n",
    "from torch_dataset import SAE_dataset\n",
    "\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    ModelSummary,\n",
    "    StochasticWeightAveraging\n",
    ")\n",
    "\n",
    "import mlflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94878e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MLFlow Logger\n",
    "\n",
    "seed_everything(42) # Reproducibility \n",
    "experiment_name = \"emb256\"\n",
    "run_name = f\"{experiment_name}_bs64\"\n",
    "tracking_uri = \"file:./sae_experiments\"\n",
    "\n",
    "mlflow_logger = MLFlowLogger(\n",
    "    experiment_name=experiment_name,\n",
    "    run_name=run_name,\n",
    "    tracking_uri=tracking_uri\n",
    ")\n",
    "\n",
    "# Hyperparameters\n",
    "hparams = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 20,\n",
    "    \"patience\": 3,\n",
    "    \"dimension_list\": [11, 16, 32, 64, 128, 256]\n",
    "}\n",
    "mlflow_logger.log_hyperparams(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce500d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source \n",
    "root = \"./data\"\n",
    "split_root_sae = \"sae_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459fbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataloader\n",
    "train_ds = SAE_dataset(df_path=os.path.join(root, split_root_sae, \"train.csv\"))\n",
    "val_ds   = SAE_dataset(df_path=os.path.join(root, split_root_sae, \"val.csv\"))\n",
    "test_ds  = SAE_dataset(df_path=os.path.join(root, split_root_sae, \"test.csv\"))\n",
    "\n",
    "batch_size = hparams[\"batch_size\"]\n",
    "train_ld = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True, num_workers=4, persistent_workers=True)\n",
    "val_ld   = DataLoader(dataset=val_ds, batch_size=batch_size, shuffle=False, num_workers=4, persistent_workers=True)\n",
    "test_ld  = DataLoader(dataset=test_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de086280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "dim_list = hparams['dimension_list']\n",
    "lr = hparams['lr']\n",
    "sparse_autoencoder = SAE_wrapper(dim_list=dim_list, lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81768fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks \n",
    "check_point_name = f\"best-checkpoint_{experiment_name}\"\n",
    "\n",
    "training_callbacks = [\n",
    "        EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=hparams['patience']),\n",
    "        StochasticWeightAveraging(swa_lrs=1e-2),\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "        ModelCheckpoint(\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1,\n",
    "            dirpath=\"sae_checkpoints/\",\n",
    "            filename=f\"best-checkpoint_{experiment_name}\"\n",
    "        ),\n",
    "        ModelSummary(-1)    \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "torch.cuda.empty_cache()  \n",
    "trainer = Trainer(\n",
    "    logger=mlflow_logger,\n",
    "    callbacks=training_callbacks,\n",
    "    max_epochs=hparams[\"epochs\"],\n",
    "    log_every_n_steps=1,\n",
    ")\n",
    "\n",
    "trainer.fit(model=sparse_autoencoder,\n",
    "            train_dataloaders=train_ld,\n",
    "            val_dataloaders= val_ld, \n",
    "            ckpt_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c608713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing \n",
    "trainer.test(model=sparse_autoencoder, \n",
    "        dataloaders=test_ld, \n",
    "        ckpt_path=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
